{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf34c586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mindbox_product_category_pairs</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x109a00c90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"mindbox_product_category_pairs\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089b9395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, LongType, StringType\n",
    ")\n",
    "\n",
    "product_schema = StructType([\n",
    "    StructField(\"id\", LongType(), nullable=False),\n",
    "    StructField(\"name\", StringType(), nullable=False),\n",
    "])\n",
    "\n",
    "category_schema = StructType([\n",
    "    StructField(\"id\", LongType(), nullable=False),\n",
    "    StructField(\"name\", StringType(), nullable=False),\n",
    "])\n",
    "\n",
    "product_category_schema = StructType([\n",
    "    StructField(\"product_id\", LongType(), nullable=False),\n",
    "    StructField(\"category_id\", LongType(), nullable=False),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3816f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_data = [\n",
    "    {\"id\": 1, \"name\": \"Phone\"},\n",
    "    {\"id\": 2, \"name\": \"Laptop\"},\n",
    "    {\"id\": 3, \"name\": \"Book\"},\n",
    "    {\"id\": 4, \"name\": \"Table\"},\n",
    "]\n",
    "\n",
    "categories_data = [\n",
    "    {\"id\": 10, \"name\": \"Electronics\"},\n",
    "    {\"id\": 20, \"name\": \"Furniture\"},\n",
    "]\n",
    "\n",
    "product_categories_data = [\n",
    "    {\"product_id\": 1, \"category_id\": 10},\n",
    "    {\"product_id\": 2, \"category_id\": 10},\n",
    "    {\"product_id\": 4, \"category_id\": 20},\n",
    "    {\"product_id\": 1, \"category_id\": 10},\n",
    "    {\"product_id\": 3, \"category_id\": 777},\n",
    "    {\"product_id\": 999, \"category_id\": 10},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e8795d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = spark.createDataFrame(products_data, schema=product_schema)\n",
    "categories = spark.createDataFrame(categories_data, schema=category_schema)\n",
    "product_categories = spark.createDataFrame(product_categories_data, schema=product_category_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251ea99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products\n",
      "+---+------+\n",
      "|id |name  |\n",
      "+---+------+\n",
      "|1  |Phone |\n",
      "|2  |Laptop|\n",
      "|3  |Book  |\n",
      "|4  |Table |\n",
      "+---+------+\n",
      "\n",
      "categories\n",
      "+---+-----------+\n",
      "|id |name       |\n",
      "+---+-----------+\n",
      "|10 |Electronics|\n",
      "|20 |Furniture  |\n",
      "+---+-----------+\n",
      "\n",
      "product_categories\n",
      "+----------+-----------+\n",
      "|product_id|category_id|\n",
      "+----------+-----------+\n",
      "|1         |10         |\n",
      "|2         |10         |\n",
      "|4         |20         |\n",
      "|1         |10         |\n",
      "|3         |777        |\n",
      "|999       |10         |\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"products\")\n",
    "products.show(truncate=False)\n",
    "\n",
    "print(\"categories\")\n",
    "categories.show(truncate=False)\n",
    "\n",
    "print(\"product_categories\")\n",
    "product_categories.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "829d9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def product_category_pairs(\n",
    "    products_df: DataFrame,\n",
    "    categories_df: DataFrame,\n",
    "    product_categories_df: DataFrame\n",
    ") -> DataFrame:\n",
    "\n",
    "    pc_dedup = (\n",
    "        product_categories_df\n",
    "        .select(\"product_id\", \"category_id\")\n",
    "        .dropDuplicates([\"product_id\", \"category_id\"])\n",
    "    )\n",
    "\n",
    "    joined = (\n",
    "        products_df.alias(\"p\")\n",
    "        .join(pc_dedup.alias(\"pc\"), col(\"p.id\") == col(\"pc.product_id\"), how=\"left\")\n",
    "    )\n",
    "\n",
    "    with_cats = (\n",
    "        joined\n",
    "        .join(categories_df.alias(\"c\"), col(\"pc.category_id\") == col(\"c.id\"), how=\"left\")\n",
    "    )\n",
    "\n",
    "    result = with_cats.select(\n",
    "        col(\"p.id\").alias(\"product_id\"),\n",
    "        col(\"p.name\").alias(\"product_name\"),\n",
    "        col(\"c.id\").alias(\"category_id\"),\n",
    "        col(\"c.name\").alias(\"category_name\"),\n",
    "    )\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8ce6066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+-------------+\n",
      "|product_id|product_name|category_id|category_name|\n",
      "+----------+------------+-----------+-------------+\n",
      "|1         |Phone       |10         |Electronics  |\n",
      "|2         |Laptop      |10         |Electronics  |\n",
      "|3         |Book        |NULL       |NULL         |\n",
      "|4         |Table       |20         |Furniture    |\n",
      "+----------+------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = product_category_pairs(products, categories, product_categories)\n",
    "\n",
    "res_ordered = res.orderBy(\"product_id\", \"category_id\")\n",
    "res_ordered.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d86de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Все проверки пройдены\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert res.count() == products.count() == 4\n",
    "\n",
    "book_rows = res.filter((col(\"product_id\") == 3) & col(\"category_id\").isNull() & col(\"category_name\").isNull())\n",
    "assert book_rows.count() == 1\n",
    "\n",
    "assert res.select(\"product_id\", \"category_id\").dropDuplicates().count() == res.count()\n",
    "\n",
    "expected = {\n",
    "    (1, \"Phone\", 10, \"Electronics\"),\n",
    "    (2, \"Laptop\", 10, \"Electronics\"),\n",
    "    (3, \"Book\",  None, None),\n",
    "    (4, \"Table\", 20, \"Furniture\"),\n",
    "}\n",
    "actual = set(\n",
    "    (r[\"product_id\"], r[\"product_name\"], r[\"category_id\"], r[\"category_name\"])\n",
    "    for r in res.collect()\n",
    ")\n",
    "assert actual == expected\n",
    "\n",
    "print(\"Все проверки пройдены\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "268ba3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "products.createOrReplaceTempView(\"products\")\n",
    "categories.createOrReplaceTempView(\"categories\")\n",
    "product_categories.createOrReplaceTempView(\"product_categories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe885bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+-------------+\n",
      "|product_id|product_name|category_id|category_name|\n",
      "+----------+------------+-----------+-------------+\n",
      "|1         |Phone       |10         |Electronics  |\n",
      "|2         |Laptop      |10         |Electronics  |\n",
      "|3         |Book        |NULL       |NULL         |\n",
      "|4         |Table       |20         |Furniture    |\n",
      "+----------+------------+-----------+-------------+\n",
      "\n",
      "✓ SQL вывод совпадает с DataFrame API\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "sql_res = spark.sql(\"\"\"\n",
    "WITH pc_dedup AS (\n",
    "    SELECT DISTINCT product_id, category_id\n",
    "    FROM product_categories\n",
    ")\n",
    "SELECT\n",
    "    p.id  AS product_id,\n",
    "    p.name AS product_name,\n",
    "    c.id  AS category_id,\n",
    "    c.name AS category_name\n",
    "FROM products p\n",
    "LEFT JOIN pc_dedup pc\n",
    "    ON p.id = pc.product_id\n",
    "LEFT JOIN categories c\n",
    "    ON pc.category_id = c.id\n",
    "ORDER BY product_id, category_id\n",
    "\"\"\")\n",
    "\n",
    "sql_res.show(truncate=False)\n",
    "\n",
    "api_res = product_category_pairs(products, categories, product_categories).orderBy(\"product_id\",\"category_id\")\n",
    "assert api_res.collect() == sql_res.collect()\n",
    "print(\"SQL вывод совпадает с DataFrame API\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
